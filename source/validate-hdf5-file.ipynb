{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "false-voltage",
   "metadata": {},
   "source": [
    "# Validation of the HDF5 file\n",
    "\n",
    "In this section, the processing from the previous section is validated against the previous way, developed by Shaheen. This is done to ensure, that the code snippets in the previous section collect the same data and produce a similar output file as before. However, it is worth to note, that the files differe significantly, as with the new version using `paat`, we are saving just the information from the ActiGraph log file and create the time vector based on the meta data we stored previously. This has the advantage to save the space of the timestamp vector which still has a `n_samples / hz` length, with `n_samples` being the number of observations of the acceleration data and `hz` being the sampling rate.\n",
    "\n",
    "Therefore, the main objective of this section is to check that the data from all subjects is also stored in the new file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "loaded-laser",
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "import os\n",
    "\n",
    "# Set file path to relevant files\n",
    "OLD_HDF5_FILEPATH = os.path.join(os.sep, 'run', 'media', 'msw', 'LaCie', 'ACTIGRAPH_TU7.hdf5')\n",
    "NEW_HDF5_FILEPATH = os.path.join(os.sep, 'run', 'media', 'msw', 'LaCie1', 'ACTIGRAPH_TU7.hdf5')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "local-attendance",
   "metadata": {},
   "source": [
    "## Load subject information"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cloudy-atlas",
   "metadata": {},
   "source": [
    "### Load the subjects from the file generated with Shaheen's code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "seasonal-vietnam",
   "metadata": {},
   "outputs": [],
   "source": [
    "with h5py.File(OLD_HDF5_FILEPATH, 'r') as old_hdf5_file:\n",
    "    old_subjects = set(old_hdf5_file.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "exceptional-electronics",
   "metadata": {},
   "source": [
    "### Load the subjects from the file generated using PAAT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "curious-forty",
   "metadata": {},
   "outputs": [],
   "source": [
    "with h5py.File(NEW_HDF5_FILEPATH, 'r') as new_hdf5_file:\n",
    "    new_subjects = set(new_hdf5_file.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "still-spanking",
   "metadata": {},
   "source": [
    "## Results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abandoned-meeting",
   "metadata": {},
   "source": [
    "### Number of subjects in each file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "herbal-poster",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6114 subjects in Shaheen's HDF5 file (/run/media/msw/LaCie/ACTIGRAPH_TU7.hdf5)\n",
      "6138 subjects in the new HDF5 file (/run/media/msw/LaCie1/ACTIGRAPH_TU7.hdf5)\n"
     ]
    }
   ],
   "source": [
    "print(\"{} subjects in Shaheen's HDF5 file ({})\".format(len(old_subjects), OLD_HDF5_FILEPATH))\n",
    "print(\"{} subjects in the new HDF5 file ({})\".format(len(new_subjects), NEW_HDF5_FILEPATH))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "italian-rabbit",
   "metadata": {},
   "source": [
    "### Comparision between the two files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "invalid-eating",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6114 subjects are in both datasets\n",
      "24 subjects are just in one of the datasets\n",
      "0 subjects are in the old, but not in the new dataset\n",
      "24 subjects are in the new, but not in the old dataset\n"
     ]
    }
   ],
   "source": [
    "print(\"{} subjects are in both datasets\".format(len(new_subjects & old_subjects)))\n",
    "print(\"{} subjects are just in one of the datasets\".format(len(old_subjects ^ new_subjects)))\n",
    "print(\"{} subjects are in the old, but not in the new dataset\".format(len(old_subjects - new_subjects)))\n",
    "print(\"{} subjects are in the new, but not in the old dataset\".format(len(new_subjects - old_subjects)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "quiet-viewer",
   "metadata": {},
   "source": [
    "### Analysis of the differences between the two files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "solar-principle",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The following subjects are just in one of the datasets:\n",
      "90156930\n",
      "90222217\n",
      "90251623\n",
      "90124622\n",
      " 91299131\n",
      "90126927\n",
      "90198027\n",
      "90025925\n",
      "90132015\n",
      "90233017\n",
      "90070622\n",
      "90179935\n",
      "90165728\n",
      "90107724\n",
      "90200314\n",
      "MOS2C02150396\n",
      "90046928\n",
      "91520421\n",
      "90198128\n",
      "90103720\n",
      "90268934\n",
      "90086023\n",
      "90043824\n",
      "92615730\n"
     ]
    }
   ],
   "source": [
    "print(\"The following subjects are just in one of the datasets:\")\n",
    "print('\\n'.join(map(str, old_subjects ^ new_subjects)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
