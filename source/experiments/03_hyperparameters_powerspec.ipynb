{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8c59386e",
   "metadata": {},
   "source": [
    "# Hyperparameter Optimization (Powerspec Model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ec887aa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import random\n",
    "import os\n",
    "import time\n",
    "import datetime\n",
    "import warnings\n",
    "from itertools import product\n",
    "\n",
    "import torch\n",
    "from torch import nn, optim\n",
    "from torch.optim.lr_scheduler import ExponentialLR\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import h5py\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "\n",
    "from utils import load_mel_data, count_parameters\n",
    "from models import *\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Make code deterministic\n",
    "SEED = 42\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "torch.cuda.manual_seed(SEED)\n",
    "torch.backends.cudnn.deterministic = True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9b25e9e",
   "metadata": {},
   "source": [
    "## Config and global variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3af3158e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set file paths\n",
    "BASE_PATH = os.path.join(\"/home/source/experiments/\")\n",
    "RESULTS_BASE_PATH = os.path.join(BASE_PATH, \"results\")\n",
    "LOG_FILE_PATH = os.path.join(BASE_PATH, \"exp03_train.log\")\n",
    "MODEL_BASE_PATH = os.path.join(BASE_PATH, 'exp03_models')\n",
    "TRAIN_RESULTS_PATH = os.path.join(RESULTS_BASE_PATH, \"exp03_train.csv\")\n",
    "TEST_RESULTS_PATH = os.path.join(RESULTS_BASE_PATH, \"exp03_test.csv\")\n",
    "\n",
    "# Logging config\n",
    "logging.basicConfig(level=logging.INFO,\n",
    "                    filename=LOG_FILE_PATH,\n",
    "                    format='%(asctime)s.%(msecs)03d %(levelname)s %(module)s - %(funcName)s: %(message)s',\n",
    "                    datefmt='%Y-%m-%d %H:%M:%S')\n",
    "\n",
    "# Set information about the dataset\n",
    "HDF5_FILE_PATH = os.path.join(os.sep, 'home', 'data', \"ANNOTATED_BEDTIME_TU7.hdf5\")\n",
    "COLNAMES = [\"Time\", \"X\", \"Y\", \"Z\", \"Annotated Time in Bed\"]\n",
    "SAMPLE_RATE = 100\n",
    "LABEL_DICT = {False: 0, True: 1}\n",
    "EXCLUDED_DATASETS = [\"subject90067325\"]\n",
    "\n",
    "# Set information about the model, etc.\n",
    "INPUT_DIM = 160\n",
    "OUTPUT_DIM = 1\n",
    "\n",
    "DROPOUT = 0.5 # https://jmlr.org/papers/v15/srivastava14a.html\n",
    "BATCH_SIZE = 8\n",
    "CLIP = 1000\n",
    "MAX_EPOCHS = 256\n",
    "MIN_EPOCHS = 0\n",
    "LR_DECAY = .9\n",
    "REVERSE = False\n",
    "\n",
    "# Combinations to test\n",
    "MODELS = [MLP, RNN, LSTM]\n",
    "HID_DIM = [1,2,4,8,16,32,64]\n",
    "N_LAYERS = [1,2,4]\n",
    "INIT_LR = [.7]\n",
    "\n",
    "# Minimal required loss impprovement\n",
    "EPSILON = 1e-4\n",
    "\n",
    "means = torch.Tensor([ -44.4865,  -59.5069,  -66.6517,  -69.3142,  -73.4886,  -76.3867,\n",
    "                       -78.8996,  -79.9984,  -82.2940,  -84.5616,  -85.4373,  -87.6441,\n",
    "                       -89.6699,  -90.6575,  -92.5189,  -94.3737,  -95.0330,  -96.6376,\n",
    "                       -98.0835,  -98.6270,  -99.1676, -100.4611, -101.6439, -102.1052,\n",
    "                      -102.5688, -103.6380, -104.6083, -104.9140, -105.2301, -106.0782,\n",
    "                      -106.3457, -106.5847, -106.8263, -107.0242, -107.6015, -107.7007,\n",
    "                      -107.7551, -108.1157, -107.9962, -107.4323,  -43.0569,  -59.5251,\n",
    "                       -67.3526,  -70.2022,  -74.8481,  -78.0362,  -80.5892,  -81.7762,\n",
    "                       -83.7894,  -85.6536,  -86.4882,  -88.3413,  -89.9654,  -90.6949,\n",
    "                       -92.0792,  -93.7075,  -94.1243,  -95.6003,  -96.9382,  -97.5214,\n",
    "                       -98.0292,  -99.3300, -100.2594, -100.6239, -100.9032, -101.8789,\n",
    "                      -103.0002, -103.3289, -103.5210, -104.2072, -104.3552, -104.5816,\n",
    "                      -104.8962, -105.0697, -105.5263, -105.4751, -105.5339, -105.9084,\n",
    "                      -105.7753, -105.1467,  -38.7873,  -53.8217,  -62.2838,  -65.5735,\n",
    "                       -70.3005,  -73.6778,  -76.3870,  -77.4950,  -79.6522,  -81.6870,\n",
    "                       -82.3242,  -84.2133,  -85.9567,  -86.7088,  -88.3639,  -90.0263,\n",
    "                       -90.5861,  -92.0502,  -93.4181,  -93.8691,  -94.4211,  -95.7346,\n",
    "                       -96.9019,  -97.4235,  -97.9199,  -99.0181, -100.0482, -100.3988,\n",
    "                      -100.7505, -101.6511, -102.0045, -102.3397, -102.6644, -102.9065,\n",
    "                      -103.5155, -103.6391, -103.7331, -104.1512, -104.0756, -103.5054,\n",
    "                       -91.2349,  -99.5667, -101.7370, -100.9673, -102.9374, -103.6892,\n",
    "                      -104.3837, -103.5328, -104.0643, -104.7086, -104.6865, -106.2458,\n",
    "                      -107.3120, -107.8856, -109.0863, -110.7779, -111.1444, -112.5662,\n",
    "                      -113.9854, -114.4069, -114.9294, -116.3273, -117.2952, -117.9790,\n",
    "                      -118.3448, -119.2901, -120.3042, -120.5012, -120.7670, -121.6727,\n",
    "                      -122.0382, -122.2133, -122.4182, -122.6655, -123.3417, -123.3857,\n",
    "                      -123.3487, -123.7909, -123.8518, -123.2396])\n",
    "stds = torch.Tensor([15.5046, 15.3608, 16.0750, 16.4421, 15.7462, 15.9030, 16.2268, 16.3318,\n",
    "                     16.1988, 16.0585, 15.8400, 15.5930, 15.3356, 14.9931, 14.6579, 14.3591,\n",
    "                     14.0773, 13.8462, 13.6614, 13.4152, 13.1776, 12.9772, 12.7750, 12.5924,\n",
    "                     12.3934, 12.2089, 12.0475, 11.9041, 11.7766, 11.6891, 11.6017, 11.5038,\n",
    "                     11.4223, 11.3544, 11.3014, 11.2560, 11.2241, 11.2038, 11.1968, 11.1596,\n",
    "                     18.5531, 18.8339, 19.7249, 20.1258, 19.7921, 19.5611, 19.1572, 19.1398,\n",
    "                     19.2797, 18.9888, 18.9910, 18.9928, 18.3535, 18.2509, 17.5982, 17.3483,\n",
    "                     16.8869, 16.5173, 16.2034, 15.8361, 15.5189, 15.3361, 14.8879, 14.8251,\n",
    "                     14.5224, 14.2143, 14.0855, 13.8587, 13.6569, 13.5621, 13.4596, 13.2743,\n",
    "                     13.0891, 12.9864, 12.9758, 12.8617, 12.7709, 12.6871, 12.7386, 12.6859,\n",
    "                     13.0402, 13.1427, 13.3539, 13.5384, 12.9476, 12.8824, 13.0041, 13.0158,\n",
    "                     13.0604, 13.1545, 13.1928, 13.2617, 13.2320, 13.0971, 12.8899, 12.7291,\n",
    "                     12.5583, 12.3833, 12.2780, 12.1346, 12.0020, 11.9203, 11.8031, 11.7010,\n",
    "                     11.5610, 11.4368, 11.3395, 11.2283, 11.1275, 11.0572, 10.9849, 10.9131,\n",
    "                     10.8662, 10.8275, 10.7903, 10.7451, 10.7291, 10.7357, 10.7697, 10.7465,\n",
    "                     16.6599, 20.7126, 25.2049, 26.0657, 25.0948, 24.5251, 23.9681, 23.7936,\n",
    "                     23.6884, 23.1676, 22.8169, 22.4963, 21.6597, 20.9830, 20.1299, 19.4319,\n",
    "                     18.6604, 17.9222, 17.2849, 16.6072, 15.9724, 15.4307, 14.7922, 14.2724,\n",
    "                     13.6931, 13.1300, 12.6672, 12.1897, 11.7421, 11.3323, 10.9345, 10.5220,\n",
    "                     10.1526,  9.8123,  9.5070,  9.2037,  8.9509,  8.7694,  8.6179,  8.4587])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6081bdf5",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "018fd9be",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1f1caf5c36c84e36b3c0c412b7a458d8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading data:   0%|          | 0/444 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "means = tensor([ -44.4865,  -59.5069,  -66.6517,  -69.3142,  -73.4886,  -76.3867,\n",
      "         -78.8996,  -79.9984,  -82.2940,  -84.5616,  -85.4373,  -87.6441,\n",
      "         -89.6699,  -90.6575,  -92.5189,  -94.3737,  -95.0330,  -96.6376,\n",
      "         -98.0835,  -98.6270,  -99.1676, -100.4611, -101.6439, -102.1052,\n",
      "        -102.5688, -103.6380, -104.6083, -104.9140, -105.2301, -106.0782,\n",
      "        -106.3457, -106.5847, -106.8263, -107.0242, -107.6015, -107.7007,\n",
      "        -107.7551, -108.1157, -107.9962, -107.4323,  -43.0569,  -59.5251,\n",
      "         -67.3526,  -70.2022,  -74.8481,  -78.0362,  -80.5892,  -81.7762,\n",
      "         -83.7894,  -85.6536,  -86.4882,  -88.3413,  -89.9654,  -90.6949,\n",
      "         -92.0792,  -93.7075,  -94.1243,  -95.6003,  -96.9382,  -97.5214,\n",
      "         -98.0292,  -99.3300, -100.2594, -100.6239, -100.9032, -101.8789,\n",
      "        -103.0002, -103.3289, -103.5210, -104.2072, -104.3552, -104.5816,\n",
      "        -104.8962, -105.0697, -105.5263, -105.4751, -105.5339, -105.9084,\n",
      "        -105.7753, -105.1467,  -38.7873,  -53.8217,  -62.2838,  -65.5735,\n",
      "         -70.3005,  -73.6778,  -76.3870,  -77.4950,  -79.6522,  -81.6870,\n",
      "         -82.3242,  -84.2133,  -85.9567,  -86.7088,  -88.3639,  -90.0263,\n",
      "         -90.5861,  -92.0502,  -93.4181,  -93.8691,  -94.4211,  -95.7346,\n",
      "         -96.9019,  -97.4235,  -97.9199,  -99.0181, -100.0482, -100.3988,\n",
      "        -100.7505, -101.6511, -102.0045, -102.3397, -102.6644, -102.9065,\n",
      "        -103.5155, -103.6391, -103.7331, -104.1512, -104.0756, -103.5054,\n",
      "         -91.2349,  -99.5667, -101.7370, -100.9673, -102.9374, -103.6892,\n",
      "        -104.3837, -103.5328, -104.0643, -104.7086, -104.6865, -106.2458,\n",
      "        -107.3120, -107.8856, -109.0863, -110.7779, -111.1444, -112.5662,\n",
      "        -113.9854, -114.4069, -114.9294, -116.3273, -117.2952, -117.9790,\n",
      "        -118.3448, -119.2901, -120.3042, -120.5012, -120.7670, -121.6727,\n",
      "        -122.0382, -122.2133, -122.4182, -122.6655, -123.3417, -123.3857,\n",
      "        -123.3487, -123.7909, -123.8518, -123.2396], dtype=torch.float64); stds = tensor([15.5046, 15.3608, 16.0750, 16.4421, 15.7462, 15.9030, 16.2268, 16.3318,\n",
      "        16.1988, 16.0585, 15.8400, 15.5930, 15.3356, 14.9931, 14.6579, 14.3591,\n",
      "        14.0773, 13.8462, 13.6614, 13.4152, 13.1776, 12.9772, 12.7750, 12.5924,\n",
      "        12.3934, 12.2089, 12.0475, 11.9041, 11.7766, 11.6891, 11.6017, 11.5038,\n",
      "        11.4223, 11.3544, 11.3014, 11.2560, 11.2241, 11.2038, 11.1968, 11.1596,\n",
      "        18.5531, 18.8339, 19.7249, 20.1258, 19.7921, 19.5611, 19.1572, 19.1398,\n",
      "        19.2797, 18.9888, 18.9910, 18.9928, 18.3535, 18.2509, 17.5982, 17.3483,\n",
      "        16.8869, 16.5173, 16.2034, 15.8361, 15.5189, 15.3361, 14.8879, 14.8251,\n",
      "        14.5224, 14.2143, 14.0855, 13.8587, 13.6569, 13.5621, 13.4596, 13.2743,\n",
      "        13.0891, 12.9864, 12.9758, 12.8617, 12.7709, 12.6871, 12.7386, 12.6859,\n",
      "        13.0402, 13.1427, 13.3539, 13.5384, 12.9476, 12.8824, 13.0041, 13.0158,\n",
      "        13.0604, 13.1545, 13.1928, 13.2617, 13.2320, 13.0971, 12.8899, 12.7291,\n",
      "        12.5583, 12.3833, 12.2780, 12.1346, 12.0020, 11.9203, 11.8031, 11.7010,\n",
      "        11.5610, 11.4368, 11.3395, 11.2283, 11.1275, 11.0572, 10.9849, 10.9131,\n",
      "        10.8662, 10.8275, 10.7903, 10.7451, 10.7291, 10.7357, 10.7697, 10.7465,\n",
      "        16.6599, 20.7126, 25.2049, 26.0657, 25.0948, 24.5251, 23.9681, 23.7936,\n",
      "        23.6884, 23.1676, 22.8169, 22.4963, 21.6597, 20.9830, 20.1299, 19.4319,\n",
      "        18.6604, 17.9222, 17.2849, 16.6072, 15.9724, 15.4307, 14.7922, 14.2724,\n",
      "        13.6931, 13.1300, 12.6672, 12.1897, 11.7421, 11.3323, 10.9345, 10.5220,\n",
      "        10.1526,  9.8123,  9.5070,  9.2037,  8.9509,  8.7694,  8.6179,  8.4587],\n",
      "       dtype=torch.float64)\n",
      "Class 0 (awake): 0.54 +/- 0.11; Class 1 (sleep): 0.46 +/- 0.11\n",
      "Normalized the input of each channel\n",
      "Loaded 444 sequences with input shape [1664 x 160] and output shape [1664]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def load_dataset(file_path, subjects, label_dict, resampled_frequency=\"1min\", means=None, stds=None):\n",
    "\n",
    "    X, y = zip(*[load_mel_data(file_path, subject, label_dict, sample_rate=SAMPLE_RATE, resampled_frequency=resampled_frequency, colnames=COLNAMES) for subject in tqdm(subjects, desc=\"Loading data\")])\n",
    "\n",
    "    lengths = [elem.shape[0] for elem in X]\n",
    "\n",
    "    X, y, lengths = zip(*[(X[ii], y[ii], lengths[ii]) for ii in np.argsort(lengths)[::-1]])\n",
    "    \n",
    "    means, stds = torch.cat(X).mean(axis=0), torch.cat(X).std(axis=0)\n",
    "    \n",
    "    logging.info(f\"means = {means}; stds = {stds}\")\n",
    "    print(f\"means = {means}; stds = {stds}\")\n",
    "\n",
    "    class_0, class_1 = zip(*[((elem == 0).sum().numpy()/elem.shape[0], (elem == 1).sum().numpy()/elem.shape[0]) for elem in y])\n",
    "    logging.info(f\"Class 0 (awake): {np.mean(class_0):.2f} +/- {np.std(class_0):.2f}; Class 1 (sleep): {np.mean(class_1):.2f} +/- {np.std(class_1):.2f}\")\n",
    "    print(f\"Class 0 (awake): {np.mean(class_0):.2f} +/- {np.std(class_0):.2f}; Class 1 (sleep): {np.mean(class_1):.2f} +/- {np.std(class_1):.2f}\")\n",
    "\n",
    "    X, y, lengths = pad_sequence(X, batch_first=True), pad_sequence(y, batch_first=True), torch.Tensor(lengths)\n",
    "\n",
    "    if means is not None and stds is not None:\n",
    "        X = (X - means) / stds\n",
    "        logging.info(\"Normalized the input of each channel\")\n",
    "        print(\"Normalized the input of each channel\")\n",
    "\n",
    "    return X, y, lengths\n",
    "\n",
    "\n",
    "# Select device (GPU if available)\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Load available subjects\n",
    "with h5py.File(HDF5_FILE_PATH) as hdf5_file:\n",
    "    subjects = [subject for subject in hdf5_file.keys() if subject not in EXCLUDED_DATASETS]\n",
    "\n",
    "# Load the data\n",
    "X, y, lengths = load_dataset(HDF5_FILE_PATH, subjects, LABEL_DICT, means=means, stds=stds)\n",
    "X, y = X.float(), y.float()\n",
    "X, y, lengths = X.to(device), y.to(device), lengths.to(device)\n",
    "assert X.shape[0] == y.shape[0]\n",
    "print(f\"Loaded {X.shape[0]} sequences with input shape [{X.shape[1]} x {X.shape[2]}] and output shape [{y.shape[1]}]\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "640309d3",
   "metadata": {},
   "source": [
    "## Create result files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d7bab0b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(TRAIN_RESULTS_PATH, \"w\") as f:\n",
    "    f.write(\"Combination,Fold,Epoch,Train Loss,Validation Loss,Hidden Dimension,Number of Layers,Initial Learning Rate,Model\\n\")\n",
    "logging.info(f\"Created training result file at {TRAIN_RESULTS_PATH}\")\n",
    "\n",
    "with open(TEST_RESULTS_PATH, \"w\") as f:\n",
    "    f.write(\"Combination,Fold,Loss,Accuracy,Precision,Recall,F1 Score,Hidden Dimension,Number of Layers,Initial Learning Rate,Model,Ellapsed Time\\n\")\n",
    "logging.info(f\"Created test result file at {TEST_RESULTS_PATH}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43f0cc59",
   "metadata": {},
   "source": [
    "## Train the models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7aed8430",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f42bbe955543421a87325b2dcb416ce2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/64 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "combinations = [(0, INIT_LR[0], 0, GLM)] + list(product(N_LAYERS, INIT_LR, HID_DIM, MODELS))\n",
    "n_combinations = len(combinations)\n",
    "for combination, (n_layers, init_lr, hid_dim, model_constr) in enumerate(tqdm(combinations)):\n",
    "\n",
    "    logging.info(f\"Combination {combination}: hid_dim = {hid_dim}; n_layers = {n_layers}; init_lr = {init_lr}; device = {device}\")\n",
    "\n",
    "    # Do 10-fold cross-validation\n",
    "    kf = KFold(n_splits=10)\n",
    "    for fold, (train_idx, test_idx) in enumerate(kf.split(np.arange(X.size(0)))):\n",
    "\n",
    "        # Create validation data\n",
    "        train_idx, valid_idx = train_test_split(np.arange(train_idx.shape[0]), test_size=0.2)\n",
    "\n",
    "        # Create model and init weights\n",
    "        model = model_constr(INPUT_DIM, hid_dim, OUTPUT_DIM, n_layers, dropout=DROPOUT, batch_first=True)\n",
    "        logging.info('Model initialized with %s trainable parameters' % count_parameters(model))\n",
    "\n",
    "        # Init loss and optimizer\n",
    "        optimizer = optim.SGD(model.parameters(), lr=init_lr) # https://arxiv.org/abs/1409.3215\n",
    "        scheduler = ExponentialLR(optimizer, gamma=LR_DECAY)\n",
    "        criterion = nn.BCELoss()\n",
    "        logging.info(f\"Start with learning rate = {init_lr} (decay = {LR_DECAY}); batch size = {BATCH_SIZE}.\")\n",
    "\n",
    "        # Create dataloaders\n",
    "        train_loader = DataLoader(TensorDataset(X[train_idx], y[train_idx], lengths[train_idx]), batch_size=BATCH_SIZE, shuffle=True)\n",
    "        valid_loader = DataLoader(TensorDataset(X[valid_idx], y[valid_idx], lengths[valid_idx]), batch_size=BATCH_SIZE)\n",
    "        test_loader = DataLoader(TensorDataset(X[test_idx], y[test_idx], lengths[test_idx]), batch_size=BATCH_SIZE)\n",
    "        logging.info(f\"Use {len(train_idx)} sequences for training, {len(valid_idx)} sequences for validation and {len(test_idx)} sequences for testing.\")\n",
    "\n",
    "        # Set path and init best loss\n",
    "        best_model_path = os.path.join(MODEL_BASE_PATH, f'{combination:02d}_best_{n_layers}l_{model.name}{hid_dim}_model_fold_{fold}.pt')\n",
    "        best_valid_loss = float('inf')\n",
    "        epoch = 0\n",
    "\n",
    "        overall_start_time = time.time()\n",
    "\n",
    "        # Evaluate model without any training\n",
    "        train_loss, _ = evaluate(model, train_loader, criterion)\n",
    "        valid_loss, _ = evaluate(model, valid_loader, criterion)\n",
    "\n",
    "        # Save losses to result file\n",
    "        with open(TRAIN_RESULTS_PATH, \"a\") as f:\n",
    "            f.write(f\"{combination},{fold},{epoch},{train_loss},{valid_loss},{hid_dim},{n_layers},{init_lr},{model.name}\\n\")\n",
    "\n",
    "        for epoch in range(1, MAX_EPOCHS + 1):\n",
    "\n",
    "            start_time = time.time()\n",
    "\n",
    "            train_loss = train(model, train_loader, optimizer, criterion, CLIP)\n",
    "            valid_loss, _ = evaluate(model, valid_loader, criterion)\n",
    "\n",
    "            time_diff = int(time.time() - start_time)\n",
    "\n",
    "            scheduler.step()\n",
    "\n",
    "            if valid_loss + EPSILON < best_valid_loss:\n",
    "                # Save losses to result file\n",
    "                with open(TRAIN_RESULTS_PATH, \"a\") as f:\n",
    "                    f.write(f\"{combination},{fold},{epoch},{train_loss},{valid_loss},{hid_dim},{n_layers},{init_lr},{model.name}\\n\")\n",
    "\n",
    "                # Update best validation loss and save model\n",
    "                best_valid_loss = valid_loss\n",
    "                logging.info(f\"Updated best validation loss to {best_valid_loss}.\")\n",
    "                torch.save(model.state_dict(), best_model_path)\n",
    "            else:\n",
    "                logging.info(f\"End training after epoch {epoch} as validation loss does not further decrease.\")\n",
    "                logging.info(f\"Best model saved at {best_model_path}\")\n",
    "                break\n",
    "\n",
    "        time_diff = int(time.time() - overall_start_time)\n",
    "\n",
    "        # Evaluate model on test set\n",
    "        logging.info(f\"Load model from epoch {epoch-1} from {best_model_path}\")\n",
    "        model.load_state_dict(torch.load(best_model_path))\n",
    "\n",
    "        test_loss, metrics = evaluate(model, test_loader, criterion)\n",
    "        accuracy, precision, recall, f1_score = metrics\n",
    "\n",
    "        with open(TEST_RESULTS_PATH, \"a\") as f:\n",
    "            f.write(f\"{combination},{fold},{test_loss},{accuracy},{precision},{recall},{f1_score},{hid_dim},{n_layers},{init_lr},{model.name},{time_diff}\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
