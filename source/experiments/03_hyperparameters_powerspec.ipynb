{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8c59386e",
   "metadata": {},
   "source": [
    "# Hyperparameter Optimization (Powerspec Model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ec887aa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import random\n",
    "import os\n",
    "import time\n",
    "import datetime\n",
    "import warnings\n",
    "from itertools import product\n",
    "\n",
    "import torch\n",
    "from torch import nn, optim\n",
    "from torch.optim.lr_scheduler import ExponentialLR\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import h5py\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "\n",
    "from utils import load_mel_data, count_parameters\n",
    "from models import *\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Make code deterministic\n",
    "SEED = 42\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "torch.cuda.manual_seed(SEED)\n",
    "torch.backends.cudnn.deterministic = True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9b25e9e",
   "metadata": {},
   "source": [
    "## Config and global variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3af3158e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set file paths\n",
    "BASE_PATH = os.path.join(\"/home/source/experiments/\")\n",
    "RESULTS_BASE_PATH = os.path.join(BASE_PATH, \"results\")\n",
    "LOG_FILE_PATH = os.path.join(BASE_PATH, \"exp03_train.log\")\n",
    "MODEL_BASE_PATH = os.path.join(BASE_PATH, 'exp03_models')\n",
    "TRAIN_RESULTS_PATH = os.path.join(RESULTS_BASE_PATH, \"exp03_train.csv\")\n",
    "TEST_RESULTS_PATH = os.path.join(RESULTS_BASE_PATH, \"exp03_test.csv\")\n",
    "\n",
    "# Logging config\n",
    "logging.basicConfig(level=logging.INFO,\n",
    "                    filename=LOG_FILE_PATH,\n",
    "                    format='%(asctime)s.%(msecs)03d %(levelname)s %(module)s - %(funcName)s: %(message)s',\n",
    "                    datefmt='%Y-%m-%d %H:%M:%S')\n",
    "\n",
    "# Set information about the dataset\n",
    "HDF5_FILE_PATH = os.path.join(os.sep, 'home', 'data', \"ANNOTATED_BEDTIME_TU7.hdf5\")\n",
    "COLNAMES = [\"Time\", \"X\", \"Y\", \"Z\", \"Annotated Time in Bed\"]\n",
    "SAMPLE_RATE = 100\n",
    "LABEL_DICT = {False: 0, True: 1}\n",
    "EXCLUDED_DATASETS = []\n",
    "\n",
    "# Set information about the model, etc.\n",
    "INPUT_DIM = 160\n",
    "OUTPUT_DIM = 1\n",
    "\n",
    "DROPOUT = 0.5 # https://jmlr.org/papers/v15/srivastava14a.html\n",
    "BATCH_SIZE = 8\n",
    "CLIP = 1000\n",
    "MAX_EPOCHS = 256\n",
    "MIN_EPOCHS = 0\n",
    "LR_DECAY = .9\n",
    "REVERSE = False\n",
    "\n",
    "# Combinations to test\n",
    "MODELS = [MLP, RNN, LSTM]\n",
    "HID_DIM = [1,2,4,8,16,32,64]\n",
    "N_LAYERS = [1,2,4]\n",
    "INIT_LR = [.7]\n",
    "\n",
    "# Minimal required loss impprovement\n",
    "EPSILON = 1e-4\n",
    "\n",
    "means = torch.Tensor([ -48.4244,  -65.1251,  -71.5329,  -76.1376,  -79.9719,  -83.3733,\n",
    "                       -86.4463,  -89.2009,  -91.6243,  -93.1006,  -95.0616,  -97.5081,\n",
    "                       -98.9459, -100.2535, -101.4587, -101.9269, -103.0128, -104.7198,\n",
    "                      -105.6010, -105.6779, -106.4788, -107.9100, -108.5404, -108.4596,\n",
    "                      -109.0225, -110.2787, -110.0530, -110.5040, -111.6329, -111.2709,\n",
    "                      -111.6229, -111.9671, -112.2292, -113.2221, -112.7077, -112.8696,\n",
    "                      -113.0403, -113.1380, -113.2175, -113.2942,  -48.2297,  -66.3363,\n",
    "                       -73.2646,  -77.7978,  -81.1189,  -84.1860,  -86.7041,  -88.9725,\n",
    "                       -90.9699,  -92.1340,  -93.9985,  -96.3562,  -97.8235,  -99.1135,\n",
    "                      -100.1286, -100.4643, -101.3244, -103.0018, -103.9505, -104.0375,\n",
    "                      -104.8962, -106.1595, -106.6999, -106.5312, -106.8978, -108.3458,\n",
    "                      -108.1114, -108.5288, -109.7681, -109.1479, -109.5088, -109.7915,\n",
    "                      -109.8525, -111.1021, -110.4775, -110.5919, -110.9078, -110.7910,\n",
    "                      -110.9218, -111.0520,  -43.2504,  -61.6844,  -68.9458,  -73.5961,\n",
    "                       -77.0992,  -80.0608,  -82.7051,  -85.1344,  -87.3067,  -88.6262,\n",
    "                       -90.4330,  -92.7584,  -94.2015,  -95.5068,  -96.7073,  -97.2398,\n",
    "                       -98.3422, -100.0732, -100.9963, -101.1373, -101.9556, -103.4150,\n",
    "                      -104.0725, -104.0774, -104.7053, -106.0052, -105.8673, -106.3338,\n",
    "                      -107.4961, -107.1521, -107.5086, -107.8810, -108.1648, -109.1684,\n",
    "                      -108.6960, -108.9002, -109.0938, -109.1790, -109.2591, -109.3175,\n",
    "                       -88.4886,  -95.3217,  -97.4304,  -98.6252,  -99.8187, -101.9569,\n",
    "                      -103.8922, -105.9184, -107.8997, -109.0467, -110.9091, -113.2237,\n",
    "                      -114.7497, -116.0618, -117.1553, -117.7753, -118.7548, -120.5024,\n",
    "                      -121.3765, -121.2271, -122.1441, -123.5200, -124.1884, -124.2784,\n",
    "                      -124.6106, -126.1395, -125.7348, -126.0794, -127.6051, -126.9591,\n",
    "                      -127.5139, -127.9155, -127.7043, -129.1599, -128.4229, -128.5986,\n",
    "                      -129.2023, -129.0043, -129.1702, -129.2966])\n",
    "\n",
    "stds = torch.Tensor([15.2323, 16.0104, 15.9714, 16.1902, 15.9361, 15.5933, 15.1956, 14.7352,\n",
    "                     14.3270, 13.9598, 13.6914, 13.4495, 13.2140, 13.0092, 12.8071, 12.6164,\n",
    "                     12.4418, 12.3007, 12.1658, 11.9811, 11.9132, 11.8334, 11.7669, 11.7018,\n",
    "                     11.6241, 11.6008, 11.5206, 11.4817, 11.4794, 11.4014, 11.3947, 11.3801,\n",
    "                     11.3306, 11.3842, 11.3314, 11.3115, 11.3362, 11.3181, 11.2947, 11.3140,\n",
    "                     18.7676, 19.9467, 19.3003, 19.1615, 18.9609, 18.9122, 18.3342, 17.8444,\n",
    "                     17.2975, 16.7270, 16.3592, 15.8516, 15.6143, 15.3346, 14.9757, 14.8446,\n",
    "                     14.5318, 14.3890, 14.2145, 13.8998, 13.8854, 13.6931, 13.6441, 13.6196,\n",
    "                     13.3293, 13.4485, 13.1998, 13.0278, 13.2340, 12.9852, 13.0790, 13.0648,\n",
    "                     12.7679, 13.0264, 12.7902, 12.7130, 12.9849, 12.7771, 12.8141, 12.8975,\n",
    "                     12.6477, 13.1166, 12.7965, 12.9296, 13.0482, 13.1621, 13.1321, 12.9195,\n",
    "                     12.6833, 12.4614, 12.2735, 12.1418, 12.0261, 11.9286, 11.8221, 11.7176,\n",
    "                     11.5904, 11.5109, 11.4179, 11.3001, 11.2326, 11.1805, 11.1244, 11.0692,\n",
    "                     11.0040, 10.9983, 10.9474, 10.9163, 10.9429, 10.8745, 10.8632, 10.8572,\n",
    "                     10.8032, 10.8757, 10.8285, 10.8419, 10.8991, 10.8676, 10.8668, 10.8800,\n",
    "                     22.3097, 25.5176, 24.0877, 23.6057, 23.0063, 22.4626, 21.4491, 20.4060,\n",
    "                     19.4148, 18.4030, 17.5354, 16.7295, 16.0956, 15.5101, 14.9024, 14.3493,\n",
    "                     13.8040, 13.3513, 12.9347, 12.4549, 12.1130, 11.7816, 11.4755, 11.1741,\n",
    "                     10.8611, 10.6525, 10.3602, 10.1416,  9.9928,  9.7345,  9.5809,  9.4059,\n",
    "                      9.2305,  9.1791,  9.0191,  8.9312,  8.8625,  8.7818,  8.7032,  8.6692])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6081bdf5",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "018fd9be",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2e2009dfea13465fbade67609dd5d9e0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading data:   0%|          | 0/445 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "means = tensor([ -48.4244,  -65.1251,  -71.5329,  -76.1376,  -79.9719,  -83.3733,\n",
      "         -86.4463,  -89.2009,  -91.6243,  -93.1006,  -95.0616,  -97.5081,\n",
      "         -98.9459, -100.2535, -101.4587, -101.9269, -103.0128, -104.7198,\n",
      "        -105.6010, -105.6779, -106.4788, -107.9100, -108.5404, -108.4596,\n",
      "        -109.0225, -110.2787, -110.0530, -110.5040, -111.6329, -111.2709,\n",
      "        -111.6229, -111.9671, -112.2292, -113.2221, -112.7077, -112.8696,\n",
      "        -113.0403, -113.1380, -113.2175, -113.2942,  -48.2297,  -66.3363,\n",
      "         -73.2646,  -77.7978,  -81.1189,  -84.1860,  -86.7041,  -88.9725,\n",
      "         -90.9699,  -92.1340,  -93.9985,  -96.3562,  -97.8235,  -99.1135,\n",
      "        -100.1286, -100.4643, -101.3244, -103.0018, -103.9505, -104.0375,\n",
      "        -104.8962, -106.1595, -106.6999, -106.5312, -106.8978, -108.3458,\n",
      "        -108.1114, -108.5288, -109.7681, -109.1479, -109.5088, -109.7915,\n",
      "        -109.8525, -111.1021, -110.4775, -110.5919, -110.9078, -110.7910,\n",
      "        -110.9218, -111.0520,  -43.2504,  -61.6844,  -68.9458,  -73.5961,\n",
      "         -77.0992,  -80.0608,  -82.7051,  -85.1344,  -87.3067,  -88.6262,\n",
      "         -90.4330,  -92.7584,  -94.2015,  -95.5068,  -96.7073,  -97.2398,\n",
      "         -98.3422, -100.0732, -100.9963, -101.1373, -101.9556, -103.4150,\n",
      "        -104.0725, -104.0774, -104.7053, -106.0052, -105.8673, -106.3338,\n",
      "        -107.4961, -107.1521, -107.5086, -107.8810, -108.1648, -109.1684,\n",
      "        -108.6960, -108.9002, -109.0938, -109.1790, -109.2591, -109.3175,\n",
      "         -88.4886,  -95.3217,  -97.4304,  -98.6252,  -99.8187, -101.9569,\n",
      "        -103.8922, -105.9184, -107.8997, -109.0467, -110.9091, -113.2237,\n",
      "        -114.7497, -116.0618, -117.1553, -117.7753, -118.7548, -120.5024,\n",
      "        -121.3765, -121.2271, -122.1441, -123.5200, -124.1884, -124.2784,\n",
      "        -124.6106, -126.1395, -125.7348, -126.0794, -127.6051, -126.9591,\n",
      "        -127.5139, -127.9155, -127.7043, -129.1599, -128.4229, -128.5986,\n",
      "        -129.2023, -129.0043, -129.1702, -129.2966], dtype=torch.float64); stds = tensor([15.2323, 16.0104, 15.9714, 16.1902, 15.9361, 15.5933, 15.1956, 14.7352,\n",
      "        14.3270, 13.9598, 13.6914, 13.4495, 13.2140, 13.0092, 12.8071, 12.6164,\n",
      "        12.4418, 12.3007, 12.1658, 11.9811, 11.9132, 11.8334, 11.7669, 11.7018,\n",
      "        11.6241, 11.6008, 11.5206, 11.4817, 11.4794, 11.4014, 11.3947, 11.3801,\n",
      "        11.3306, 11.3842, 11.3314, 11.3115, 11.3362, 11.3181, 11.2947, 11.3140,\n",
      "        18.7676, 19.9467, 19.3003, 19.1615, 18.9609, 18.9122, 18.3342, 17.8444,\n",
      "        17.2975, 16.7270, 16.3592, 15.8516, 15.6143, 15.3346, 14.9757, 14.8446,\n",
      "        14.5318, 14.3890, 14.2145, 13.8998, 13.8854, 13.6931, 13.6441, 13.6196,\n",
      "        13.3293, 13.4485, 13.1998, 13.0278, 13.2340, 12.9852, 13.0790, 13.0648,\n",
      "        12.7679, 13.0264, 12.7902, 12.7130, 12.9849, 12.7771, 12.8141, 12.8975,\n",
      "        12.6477, 13.1166, 12.7965, 12.9296, 13.0482, 13.1621, 13.1321, 12.9195,\n",
      "        12.6833, 12.4614, 12.2735, 12.1418, 12.0261, 11.9286, 11.8221, 11.7176,\n",
      "        11.5904, 11.5109, 11.4179, 11.3001, 11.2326, 11.1805, 11.1244, 11.0692,\n",
      "        11.0040, 10.9983, 10.9474, 10.9163, 10.9429, 10.8745, 10.8632, 10.8572,\n",
      "        10.8032, 10.8757, 10.8285, 10.8419, 10.8991, 10.8676, 10.8668, 10.8800,\n",
      "        22.3097, 25.5176, 24.0877, 23.6057, 23.0063, 22.4626, 21.4491, 20.4060,\n",
      "        19.4148, 18.4030, 17.5354, 16.7295, 16.0956, 15.5101, 14.9024, 14.3493,\n",
      "        13.8040, 13.3513, 12.9347, 12.4549, 12.1130, 11.7816, 11.4755, 11.1741,\n",
      "        10.8611, 10.6525, 10.3602, 10.1416,  9.9928,  9.7345,  9.5809,  9.4059,\n",
      "         9.2305,  9.1791,  9.0191,  8.9312,  8.8625,  8.7818,  8.7032,  8.6692],\n",
      "       dtype=torch.float64)\n",
      "Class 0 (awake): 0.54 +/- 0.11; Class 1 (sleep): 0.46 +/- 0.11\n",
      "Normalized the input of each channel\n",
      "Loaded 445 sequences with input shape [1664 x 160] and output shape [1664]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def load_dataset(file_path, subjects, label_dict, resampled_frequency=\"1min\", means=None, stds=None):\n",
    "\n",
    "    X, y = zip(*[load_mel_data(file_path, subject, label_dict, sample_rate=SAMPLE_RATE, resampled_frequency=resampled_frequency, colnames=COLNAMES) for subject in tqdm(subjects, desc=\"Loading data\")])\n",
    "\n",
    "    lengths = [elem.shape[0] for elem in X]\n",
    "\n",
    "    X, y, lengths = zip(*[(X[ii], y[ii], lengths[ii]) for ii in np.argsort(lengths)[::-1]])\n",
    "    \n",
    "    means, stds = torch.cat(X).mean(axis=0), torch.cat(X).std(axis=0)\n",
    "    \n",
    "    logging.info(f\"means = {means}; stds = {stds}\")\n",
    "    print(f\"means = {means}; stds = {stds}\")\n",
    "\n",
    "    class_0, class_1 = zip(*[((elem == 0).sum().numpy()/elem.shape[0], (elem == 1).sum().numpy()/elem.shape[0]) for elem in y])\n",
    "    logging.info(f\"Class 0 (awake): {np.mean(class_0):.2f} +/- {np.std(class_0):.2f}; Class 1 (sleep): {np.mean(class_1):.2f} +/- {np.std(class_1):.2f}\")\n",
    "    print(f\"Class 0 (awake): {np.mean(class_0):.2f} +/- {np.std(class_0):.2f}; Class 1 (sleep): {np.mean(class_1):.2f} +/- {np.std(class_1):.2f}\")\n",
    "\n",
    "    X, y, lengths = pad_sequence(X, batch_first=True), pad_sequence(y, batch_first=True), torch.Tensor(lengths)\n",
    "\n",
    "    if means is not None and stds is not None:\n",
    "        X = (X - means) / stds\n",
    "        logging.info(\"Normalized the input of each channel\")\n",
    "        print(\"Normalized the input of each channel\")\n",
    "\n",
    "    return X, y, lengths\n",
    "\n",
    "\n",
    "# Select device (GPU if available)\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Load available subjects\n",
    "with h5py.File(HDF5_FILE_PATH) as hdf5_file:\n",
    "    subjects = [subject for subject in hdf5_file.keys() if subject not in EXCLUDED_DATASETS]\n",
    "\n",
    "# Load the data\n",
    "X, y, lengths = load_dataset(HDF5_FILE_PATH, subjects, LABEL_DICT, means=means, stds=stds)\n",
    "X, y = X.float(), y.float()\n",
    "X, y, lengths = X.to(device), y.to(device), lengths.to(device)\n",
    "assert X.shape[0] == y.shape[0]\n",
    "print(f\"Loaded {X.shape[0]} sequences with input shape [{X.shape[1]} x {X.shape[2]}] and output shape [{y.shape[1]}]\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "640309d3",
   "metadata": {},
   "source": [
    "## Create result files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d7bab0b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(TRAIN_RESULTS_PATH, \"w\") as f:\n",
    "    f.write(\"Combination,Fold,Epoch,Train Loss,Validation Loss,Hidden Dimension,Number of Layers,Initial Learning Rate,Model\\n\")\n",
    "logging.info(f\"Created training result file at {TRAIN_RESULTS_PATH}\")\n",
    "\n",
    "with open(TEST_RESULTS_PATH, \"w\") as f:\n",
    "    f.write(\"Combination,Fold,Loss,Accuracy,Precision,Recall,F1 Score,Hidden Dimension,Number of Layers,Initial Learning Rate,Model,Ellapsed Time\\n\")\n",
    "logging.info(f\"Created test result file at {TEST_RESULTS_PATH}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43f0cc59",
   "metadata": {},
   "source": [
    "## Train the models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7aed8430",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8976fde8db9d4713a03c16863ad91d10",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/64 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "combinations = [(0, INIT_LR[0], 0, GLM)] + list(product(N_LAYERS, INIT_LR, HID_DIM, MODELS))\n",
    "n_combinations = len(combinations)\n",
    "for combination, (n_layers, init_lr, hid_dim, model_constr) in enumerate(tqdm(combinations)):\n",
    "\n",
    "    logging.info(f\"Combination {combination}: hid_dim = {hid_dim}; n_layers = {n_layers}; init_lr = {init_lr}; device = {device}\")\n",
    "\n",
    "    # Do 10-fold cross-validation\n",
    "    kf = KFold(n_splits=10)\n",
    "    for fold, (train_idx, test_idx) in enumerate(kf.split(np.arange(X.size(0)))):\n",
    "\n",
    "        # Create validation data\n",
    "        train_idx, valid_idx = train_test_split(np.arange(train_idx.shape[0]), test_size=0.2)\n",
    "\n",
    "        # Create model and init weights\n",
    "        model = model_constr(INPUT_DIM, hid_dim, OUTPUT_DIM, n_layers, dropout=DROPOUT, batch_first=True)\n",
    "        logging.info('Model initialized with %s trainable parameters' % count_parameters(model))\n",
    "\n",
    "        # Init loss and optimizer\n",
    "        optimizer = optim.SGD(model.parameters(), lr=init_lr) # https://arxiv.org/abs/1409.3215\n",
    "        scheduler = ExponentialLR(optimizer, gamma=LR_DECAY)\n",
    "        criterion = nn.BCELoss()\n",
    "        logging.info(f\"Start with learning rate = {init_lr} (decay = {LR_DECAY}); batch size = {BATCH_SIZE}.\")\n",
    "\n",
    "        # Create dataloaders\n",
    "        train_loader = DataLoader(TensorDataset(X[train_idx], y[train_idx], lengths[train_idx]), batch_size=BATCH_SIZE, shuffle=True)\n",
    "        valid_loader = DataLoader(TensorDataset(X[valid_idx], y[valid_idx], lengths[valid_idx]), batch_size=BATCH_SIZE)\n",
    "        test_loader = DataLoader(TensorDataset(X[test_idx], y[test_idx], lengths[test_idx]), batch_size=BATCH_SIZE)\n",
    "        logging.info(f\"Use {len(train_idx)} sequences for training, {len(valid_idx)} sequences for validation and {len(test_idx)} sequences for testing.\")\n",
    "\n",
    "        # Set path and init best loss\n",
    "        best_model_path = os.path.join(MODEL_BASE_PATH, f'{combination:02d}_best_{n_layers}l_{model.name}{hid_dim}_model_fold_{fold}.pt')\n",
    "        best_valid_loss = float('inf')\n",
    "        epoch = 0\n",
    "\n",
    "        overall_start_time = time.time()\n",
    "\n",
    "        # Evaluate model without any training\n",
    "        train_loss, _ = evaluate(model, train_loader, criterion)\n",
    "        valid_loss, _ = evaluate(model, valid_loader, criterion)\n",
    "\n",
    "        # Save losses to result file\n",
    "        with open(TRAIN_RESULTS_PATH, \"a\") as f:\n",
    "            f.write(f\"{combination},{fold},{epoch},{train_loss},{valid_loss},{hid_dim},{n_layers},{init_lr},{model.name}\\n\")\n",
    "\n",
    "        for epoch in range(1, MAX_EPOCHS + 1):\n",
    "\n",
    "            start_time = time.time()\n",
    "\n",
    "            train_loss = train(model, train_loader, optimizer, criterion, CLIP)\n",
    "            valid_loss, _ = evaluate(model, valid_loader, criterion)\n",
    "\n",
    "            time_diff = int(time.time() - start_time)\n",
    "\n",
    "            scheduler.step()\n",
    "\n",
    "            if valid_loss + EPSILON < best_valid_loss:\n",
    "                # Save losses to result file\n",
    "                with open(TRAIN_RESULTS_PATH, \"a\") as f:\n",
    "                    f.write(f\"{combination},{fold},{epoch},{train_loss},{valid_loss},{hid_dim},{n_layers},{init_lr},{model.name}\\n\")\n",
    "\n",
    "                # Update best validation loss and save model\n",
    "                best_valid_loss = valid_loss\n",
    "                logging.info(f\"Updated best validation loss to {best_valid_loss}.\")\n",
    "                torch.save(model.state_dict(), best_model_path)\n",
    "            else:\n",
    "                logging.info(f\"End training after epoch {epoch} as validation loss does not further decrease.\")\n",
    "                logging.info(f\"Best model saved at {best_model_path}\")\n",
    "                break\n",
    "\n",
    "        time_diff = int(time.time() - overall_start_time)\n",
    "\n",
    "        # Evaluate model on test set\n",
    "        logging.info(f\"Load model from epoch {epoch-1} from {best_model_path}\")\n",
    "        model.load_state_dict(torch.load(best_model_path))\n",
    "\n",
    "        test_loss, metrics = evaluate(model, test_loader, criterion)\n",
    "        accuracy, precision, recall, f1_score = metrics\n",
    "\n",
    "        with open(TEST_RESULTS_PATH, \"a\") as f:\n",
    "            f.write(f\"{combination},{fold},{test_loss},{accuracy},{precision},{recall},{f1_score},{hid_dim},{n_layers},{init_lr},{model.name},{time_diff}\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
