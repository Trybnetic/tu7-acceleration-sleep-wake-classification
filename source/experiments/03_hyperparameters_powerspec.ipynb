{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8c59386e",
   "metadata": {},
   "source": [
    "# Hyperparameter Optimization (Powerspec Model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ec887aa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import random\n",
    "import os\n",
    "import time\n",
    "import datetime\n",
    "import warnings\n",
    "from itertools import product\n",
    "\n",
    "import torch\n",
    "from torch import nn, optim\n",
    "from torch.optim.lr_scheduler import ExponentialLR\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import h5py\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "\n",
    "from utils import load_mel_data, count_parameters\n",
    "from models import *\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Make code deterministic\n",
    "SEED = 42\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "torch.cuda.manual_seed(SEED)\n",
    "torch.backends.cudnn.deterministic = True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9b25e9e",
   "metadata": {},
   "source": [
    "## Config and global variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3af3158e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set file paths\n",
    "BASE_PATH = os.path.join(\"/home/source/experiments/\")\n",
    "RESULTS_BASE_PATH = os.path.join(BASE_PATH, \"results\")\n",
    "LOG_FILE_PATH = os.path.join(BASE_PATH, \"exp03_train.log\")\n",
    "MODEL_BASE_PATH = os.path.join(BASE_PATH, 'exp03_models')\n",
    "TRAIN_RESULTS_PATH = os.path.join(RESULTS_BASE_PATH, \"exp03_train.csv\")\n",
    "TEST_RESULTS_PATH = os.path.join(RESULTS_BASE_PATH, \"exp03_test.csv\")\n",
    "\n",
    "# Logging config\n",
    "logging.basicConfig(level=logging.INFO,\n",
    "                    filename=LOG_FILE_PATH,\n",
    "                    format='%(asctime)s.%(msecs)03d %(levelname)s %(module)s - %(funcName)s: %(message)s',\n",
    "                    datefmt='%Y-%m-%d %H:%M:%S')\n",
    "\n",
    "# Set information about the dataset\n",
    "HDF5_FILE_PATH = os.path.join(os.sep, 'home', 'data', \"ANNOTATED_BEDTIME_TU7.hdf5\")\n",
    "COLNAMES = [\"Time\", \"X\", \"Y\", \"Z\", \"Annotated Time in Bed\"]\n",
    "SAMPLE_RATE = 100\n",
    "LABEL_DICT = {False: 0, True: 1}\n",
    "EXCLUDED_DATASETS = [\"subject90067325\"]\n",
    "\n",
    "# Set information about the model, etc.\n",
    "INPUT_DIM = 160\n",
    "OUTPUT_DIM = 1\n",
    "\n",
    "DROPOUT = 0.5 # https://jmlr.org/papers/v15/srivastava14a.html\n",
    "BATCH_SIZE = 8\n",
    "CLIP = 1000\n",
    "MAX_EPOCHS = 256\n",
    "MIN_EPOCHS = 0\n",
    "LR_DECAY = .9\n",
    "REVERSE = False\n",
    "\n",
    "# Combinations to test\n",
    "MODELS = [MLP, RNN, LSTM]\n",
    "HID_DIM = [1,2,4,8,16,32,64]\n",
    "N_LAYERS = [1,2,4]\n",
    "INIT_LR = [.7]\n",
    "\n",
    "# Minimal required loss impprovement\n",
    "EPSILON = 1e-4\n",
    "\n",
    "means = torch.Tensor([ -48.4207,  -65.1218,  -71.5279,  -76.1308,  -79.9645,  -83.3663,\n",
    "                       -86.4398,  -89.1959,  -91.6206,  -93.0964,  -95.0577,  -97.5050,\n",
    "                       -98.9434, -100.2508, -101.4559, -101.9244, -103.0111, -104.7183,\n",
    "                      -105.5989, -105.6751, -106.4759, -107.9065, -108.5371, -108.4562,\n",
    "                      -109.0211, -110.2759, -110.0502, -110.5009, -111.6296, -111.2670,\n",
    "                      -111.6191, -111.9629, -112.2249, -113.2178, -112.7033, -112.8654,\n",
    "                      -113.0358, -113.1333, -113.2129, -113.2895,  -48.2245,  -66.3324,\n",
    "                       -73.2612,  -77.7942,  -81.1151,  -84.1829,  -86.7018,  -88.9712,\n",
    "                       -90.9700,  -92.1339,  -93.9986,  -96.3574,  -97.8250,  -99.1140,\n",
    "                      -100.1279, -100.4639, -101.3244, -103.0022, -103.9505, -104.0372,\n",
    "                      -104.8954, -106.1583, -106.6984, -106.5298, -106.8966, -108.3447,\n",
    "                      -108.1104, -108.5275, -109.7666, -109.1461, -109.5073, -109.7905,\n",
    "                      -109.8520, -111.1019, -110.4769, -110.5905, -110.9061, -110.7892,\n",
    "                      -110.9209, -111.0517,  -43.2543,  -61.6885,  -68.9491,  -73.5991,\n",
    "                       -77.1016,  -80.0631,  -82.7077,  -85.1379,  -87.3117,  -88.6311,\n",
    "                       -90.4376,  -92.7634,  -94.2068,  -95.5118,  -96.7122,  -97.2450,\n",
    "                       -98.3478, -100.0788, -101.0015, -101.1428, -101.9611, -103.4203,\n",
    "                      -104.0778, -104.0826, -104.7114, -106.0103, -105.8721, -106.3384,\n",
    "                      -107.5007, -107.1565, -107.5132, -107.8857, -108.1693, -109.1731,\n",
    "                      -108.7007, -108.9047, -109.0983, -109.1834, -109.2635, -109.3219,\n",
    "                       -88.4789,  -95.3224,  -97.4297,  -98.6238,  -99.8170, -101.9552,\n",
    "                      -103.8918, -105.9195, -107.9017, -109.0472, -110.9086, -113.2247,\n",
    "                      -114.7520, -116.0630, -117.1561, -117.7766, -118.7566, -120.5036,\n",
    "                      -121.3769, -121.2272, -122.1442, -123.5198, -124.1882, -124.2786,\n",
    "                      -124.6115, -126.1393, -125.7334, -126.0776, -127.6043, -126.9575,\n",
    "                      -127.5121, -127.9141, -127.7025, -129.1585, -128.4213, -128.5968,\n",
    "                      -129.2008, -129.0018, -129.1680, -129.2950])\n",
    "\n",
    "stds = torch.Tensor([15.2365, 16.0121, 15.9737, 16.1929, 15.9387, 15.5965, 15.1987, 14.7376,\n",
    "                     14.3288, 13.9616, 13.6932, 13.4502, 13.2141, 13.0099, 12.8077, 12.6167,\n",
    "                     12.4420, 12.3011, 12.1666, 11.9817, 11.9137, 11.8341, 11.7676, 11.7024,\n",
    "                     11.6222, 11.6012, 11.5212, 11.4829, 11.4804, 11.4021, 11.3955, 11.3809,\n",
    "                     11.3314, 11.3852, 11.3326, 11.3130, 11.3374, 11.3191, 11.2958, 11.3150,\n",
    "                     18.7619, 19.9428, 19.2959, 19.1569, 18.9576, 18.9095, 18.3317, 17.8413,\n",
    "                     17.2935, 16.7246, 16.3572, 15.8488, 15.6116, 15.3324, 14.9735, 14.8424,\n",
    "                     14.5291, 14.3861, 14.2124, 13.8977, 13.8832, 13.6913, 13.6424, 13.6181,\n",
    "                     13.3272, 13.4469, 13.1981, 13.0259, 13.2324, 12.9835, 13.0779, 13.0635,\n",
    "                     12.7663, 13.0255, 12.7892, 12.7116, 12.9838, 12.7755, 12.8132, 12.8965,\n",
    "                     12.6507, 13.1202, 12.8005, 12.9337, 13.0524, 13.1663, 13.1359, 12.9216,\n",
    "                     12.6842, 12.4627, 12.2747, 12.1424, 12.0269, 11.9295, 11.8228, 11.7181,\n",
    "                     11.5907, 11.5112, 11.4187, 11.3004, 11.2326, 11.1814, 11.1253, 11.0703,\n",
    "                     11.0036, 10.9998, 10.9487, 10.9178, 10.9446, 10.8762, 10.8651, 10.8592,\n",
    "                     10.8049, 10.8777, 10.8306, 10.8438, 10.9010, 10.8696, 10.8686, 10.8816,\n",
    "                     22.3002, 25.5131, 24.0863, 23.6062, 23.0077, 22.4646, 21.4507, 20.4049,\n",
    "                     19.4103, 18.3997, 17.5340, 16.7272, 16.0919, 15.5063, 14.8996, 14.3464,\n",
    "                     13.8004, 13.3478, 12.9319, 12.4513, 12.1094, 11.7793, 11.4736, 11.1728,\n",
    "                     10.8574, 10.6516, 10.3594, 10.1412,  9.9928,  9.7343,  9.5811,  9.4065,\n",
    "                      9.2308,  9.1794,  9.0196,  8.9316,  8.8628,  8.7821,  8.7035,  8.6694])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6081bdf5",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "018fd9be",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3732e00e8dfb45b798de089f81123bb9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading data:   0%|          | 0/444 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "means = tensor([ -48.4207,  -65.1218,  -71.5279,  -76.1308,  -79.9645,  -83.3663,\n",
      "         -86.4398,  -89.1959,  -91.6206,  -93.0964,  -95.0577,  -97.5050,\n",
      "         -98.9434, -100.2508, -101.4559, -101.9244, -103.0111, -104.7183,\n",
      "        -105.5989, -105.6751, -106.4759, -107.9065, -108.5371, -108.4562,\n",
      "        -109.0211, -110.2759, -110.0502, -110.5009, -111.6296, -111.2670,\n",
      "        -111.6191, -111.9629, -112.2249, -113.2178, -112.7033, -112.8654,\n",
      "        -113.0358, -113.1333, -113.2129, -113.2895,  -48.2245,  -66.3324,\n",
      "         -73.2612,  -77.7942,  -81.1151,  -84.1829,  -86.7018,  -88.9712,\n",
      "         -90.9700,  -92.1339,  -93.9986,  -96.3574,  -97.8250,  -99.1140,\n",
      "        -100.1279, -100.4639, -101.3244, -103.0022, -103.9505, -104.0372,\n",
      "        -104.8954, -106.1583, -106.6984, -106.5298, -106.8966, -108.3447,\n",
      "        -108.1104, -108.5275, -109.7666, -109.1461, -109.5073, -109.7905,\n",
      "        -109.8520, -111.1019, -110.4769, -110.5905, -110.9061, -110.7892,\n",
      "        -110.9209, -111.0517,  -43.2543,  -61.6885,  -68.9491,  -73.5991,\n",
      "         -77.1016,  -80.0631,  -82.7077,  -85.1379,  -87.3117,  -88.6311,\n",
      "         -90.4376,  -92.7634,  -94.2068,  -95.5118,  -96.7122,  -97.2450,\n",
      "         -98.3478, -100.0788, -101.0015, -101.1428, -101.9611, -103.4203,\n",
      "        -104.0778, -104.0826, -104.7114, -106.0103, -105.8721, -106.3384,\n",
      "        -107.5007, -107.1565, -107.5132, -107.8857, -108.1693, -109.1731,\n",
      "        -108.7007, -108.9047, -109.0983, -109.1834, -109.2635, -109.3219,\n",
      "         -88.4789,  -95.3224,  -97.4297,  -98.6238,  -99.8170, -101.9552,\n",
      "        -103.8918, -105.9195, -107.9017, -109.0472, -110.9086, -113.2247,\n",
      "        -114.7520, -116.0630, -117.1561, -117.7766, -118.7566, -120.5036,\n",
      "        -121.3769, -121.2272, -122.1442, -123.5198, -124.1882, -124.2786,\n",
      "        -124.6115, -126.1393, -125.7334, -126.0776, -127.6043, -126.9575,\n",
      "        -127.5121, -127.9141, -127.7025, -129.1585, -128.4213, -128.5968,\n",
      "        -129.2008, -129.0018, -129.1680, -129.2950], dtype=torch.float64); stds = tensor([15.2365, 16.0121, 15.9737, 16.1929, 15.9387, 15.5965, 15.1987, 14.7376,\n",
      "        14.3288, 13.9616, 13.6932, 13.4502, 13.2141, 13.0099, 12.8077, 12.6167,\n",
      "        12.4420, 12.3011, 12.1666, 11.9817, 11.9137, 11.8341, 11.7676, 11.7024,\n",
      "        11.6222, 11.6012, 11.5212, 11.4829, 11.4804, 11.4021, 11.3955, 11.3809,\n",
      "        11.3314, 11.3852, 11.3326, 11.3130, 11.3374, 11.3191, 11.2958, 11.3150,\n",
      "        18.7619, 19.9428, 19.2959, 19.1569, 18.9576, 18.9095, 18.3317, 17.8413,\n",
      "        17.2935, 16.7246, 16.3572, 15.8488, 15.6116, 15.3324, 14.9735, 14.8424,\n",
      "        14.5291, 14.3861, 14.2124, 13.8977, 13.8832, 13.6913, 13.6424, 13.6181,\n",
      "        13.3272, 13.4469, 13.1981, 13.0259, 13.2324, 12.9835, 13.0779, 13.0635,\n",
      "        12.7663, 13.0255, 12.7892, 12.7116, 12.9838, 12.7755, 12.8132, 12.8965,\n",
      "        12.6507, 13.1202, 12.8005, 12.9337, 13.0524, 13.1663, 13.1359, 12.9216,\n",
      "        12.6842, 12.4627, 12.2747, 12.1424, 12.0269, 11.9295, 11.8228, 11.7181,\n",
      "        11.5907, 11.5112, 11.4187, 11.3004, 11.2326, 11.1814, 11.1253, 11.0703,\n",
      "        11.0036, 10.9998, 10.9487, 10.9178, 10.9446, 10.8762, 10.8651, 10.8592,\n",
      "        10.8049, 10.8777, 10.8306, 10.8438, 10.9010, 10.8696, 10.8686, 10.8816,\n",
      "        22.3002, 25.5131, 24.0863, 23.6062, 23.0077, 22.4646, 21.4507, 20.4049,\n",
      "        19.4103, 18.3997, 17.5340, 16.7272, 16.0919, 15.5063, 14.8996, 14.3464,\n",
      "        13.8004, 13.3478, 12.9319, 12.4513, 12.1094, 11.7793, 11.4736, 11.1728,\n",
      "        10.8574, 10.6516, 10.3594, 10.1412,  9.9928,  9.7343,  9.5811,  9.4065,\n",
      "         9.2308,  9.1794,  9.0196,  8.9316,  8.8628,  8.7821,  8.7035,  8.6694],\n",
      "       dtype=torch.float64)\n",
      "Class 0 (awake): 0.54 +/- 0.11; Class 1 (sleep): 0.46 +/- 0.11\n",
      "Normalized the input of each channel\n",
      "Loaded 444 sequences with input shape [1664 x 160] and output shape [1664]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def load_dataset(file_path, subjects, label_dict, resampled_frequency=\"1min\", means=None, stds=None):\n",
    "\n",
    "    X, y = zip(*[load_mel_data(file_path, subject, label_dict, sample_rate=SAMPLE_RATE, resampled_frequency=resampled_frequency, colnames=COLNAMES) for subject in tqdm(subjects, desc=\"Loading data\")])\n",
    "\n",
    "    lengths = [elem.shape[0] for elem in X]\n",
    "\n",
    "    X, y, lengths = zip(*[(X[ii], y[ii], lengths[ii]) for ii in np.argsort(lengths)[::-1]])\n",
    "    \n",
    "    means, stds = torch.cat(X).mean(axis=0), torch.cat(X).std(axis=0)\n",
    "    \n",
    "    logging.info(f\"means = {means}; stds = {stds}\")\n",
    "    print(f\"means = {means}; stds = {stds}\")\n",
    "\n",
    "    class_0, class_1 = zip(*[((elem == 0).sum().numpy()/elem.shape[0], (elem == 1).sum().numpy()/elem.shape[0]) for elem in y])\n",
    "    logging.info(f\"Class 0 (awake): {np.mean(class_0):.2f} +/- {np.std(class_0):.2f}; Class 1 (sleep): {np.mean(class_1):.2f} +/- {np.std(class_1):.2f}\")\n",
    "    print(f\"Class 0 (awake): {np.mean(class_0):.2f} +/- {np.std(class_0):.2f}; Class 1 (sleep): {np.mean(class_1):.2f} +/- {np.std(class_1):.2f}\")\n",
    "\n",
    "    X, y, lengths = pad_sequence(X, batch_first=True), pad_sequence(y, batch_first=True), torch.Tensor(lengths)\n",
    "\n",
    "    if means is not None and stds is not None:\n",
    "        X = (X - means) / stds\n",
    "        logging.info(\"Normalized the input of each channel\")\n",
    "        print(\"Normalized the input of each channel\")\n",
    "\n",
    "    return X, y, lengths\n",
    "\n",
    "\n",
    "# Select device (GPU if available)\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Load available subjects\n",
    "with h5py.File(HDF5_FILE_PATH) as hdf5_file:\n",
    "    subjects = [subject for subject in hdf5_file.keys() if subject not in EXCLUDED_DATASETS]\n",
    "\n",
    "# Load the data\n",
    "X, y, lengths = load_dataset(HDF5_FILE_PATH, subjects, LABEL_DICT, means=means, stds=stds)\n",
    "X, y = X.float(), y.float()\n",
    "X, y, lengths = X.to(device), y.to(device), lengths.to(device)\n",
    "assert X.shape[0] == y.shape[0]\n",
    "print(f\"Loaded {X.shape[0]} sequences with input shape [{X.shape[1]} x {X.shape[2]}] and output shape [{y.shape[1]}]\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "640309d3",
   "metadata": {},
   "source": [
    "## Create result files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d7bab0b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(TRAIN_RESULTS_PATH, \"w\") as f:\n",
    "    f.write(\"Combination,Fold,Epoch,Train Loss,Validation Loss,Hidden Dimension,Number of Layers,Initial Learning Rate,Model\\n\")\n",
    "logging.info(f\"Created training result file at {TRAIN_RESULTS_PATH}\")\n",
    "\n",
    "with open(TEST_RESULTS_PATH, \"w\") as f:\n",
    "    f.write(\"Combination,Fold,Loss,Accuracy,Precision,Recall,F1 Score,Hidden Dimension,Number of Layers,Initial Learning Rate,Model,Ellapsed Time\\n\")\n",
    "logging.info(f\"Created test result file at {TEST_RESULTS_PATH}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43f0cc59",
   "metadata": {},
   "source": [
    "## Train the models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7aed8430",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8e9b4a9972924afd82bc371e3f557478",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/64 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "combinations = [(0, INIT_LR[0], 0, GLM)] + list(product(N_LAYERS, INIT_LR, HID_DIM, MODELS))\n",
    "n_combinations = len(combinations)\n",
    "for combination, (n_layers, init_lr, hid_dim, model_constr) in enumerate(tqdm(combinations)):\n",
    "\n",
    "    logging.info(f\"Combination {combination}: hid_dim = {hid_dim}; n_layers = {n_layers}; init_lr = {init_lr}; device = {device}\")\n",
    "\n",
    "    # Do 10-fold cross-validation\n",
    "    kf = KFold(n_splits=10)\n",
    "    for fold, (train_idx, test_idx) in enumerate(kf.split(np.arange(X.size(0)))):\n",
    "\n",
    "        # Create validation data\n",
    "        train_idx, valid_idx = train_test_split(np.arange(train_idx.shape[0]), test_size=0.2)\n",
    "\n",
    "        # Create model and init weights\n",
    "        model = model_constr(INPUT_DIM, hid_dim, OUTPUT_DIM, n_layers, dropout=DROPOUT, batch_first=True)\n",
    "        logging.info('Model initialized with %s trainable parameters' % count_parameters(model))\n",
    "\n",
    "        # Init loss and optimizer\n",
    "        optimizer = optim.SGD(model.parameters(), lr=init_lr) # https://arxiv.org/abs/1409.3215\n",
    "        scheduler = ExponentialLR(optimizer, gamma=LR_DECAY)\n",
    "        criterion = nn.BCELoss()\n",
    "        logging.info(f\"Start with learning rate = {init_lr} (decay = {LR_DECAY}); batch size = {BATCH_SIZE}.\")\n",
    "\n",
    "        # Create dataloaders\n",
    "        train_loader = DataLoader(TensorDataset(X[train_idx], y[train_idx], lengths[train_idx]), batch_size=BATCH_SIZE, shuffle=True)\n",
    "        valid_loader = DataLoader(TensorDataset(X[valid_idx], y[valid_idx], lengths[valid_idx]), batch_size=BATCH_SIZE)\n",
    "        test_loader = DataLoader(TensorDataset(X[test_idx], y[test_idx], lengths[test_idx]), batch_size=BATCH_SIZE)\n",
    "        logging.info(f\"Use {len(train_idx)} sequences for training, {len(valid_idx)} sequences for validation and {len(test_idx)} sequences for testing.\")\n",
    "\n",
    "        # Set path and init best loss\n",
    "        best_model_path = os.path.join(MODEL_BASE_PATH, f'{combination:02d}_best_{n_layers}l_{model.name}{hid_dim}_model_fold_{fold}.pt')\n",
    "        best_valid_loss = float('inf')\n",
    "        epoch = 0\n",
    "\n",
    "        overall_start_time = time.time()\n",
    "\n",
    "        # Evaluate model without any training\n",
    "        train_loss, _ = evaluate(model, train_loader, criterion)\n",
    "        valid_loss, _ = evaluate(model, valid_loader, criterion)\n",
    "\n",
    "        # Save losses to result file\n",
    "        with open(TRAIN_RESULTS_PATH, \"a\") as f:\n",
    "            f.write(f\"{combination},{fold},{epoch},{train_loss},{valid_loss},{hid_dim},{n_layers},{init_lr},{model.name}\\n\")\n",
    "\n",
    "        for epoch in range(1, MAX_EPOCHS + 1):\n",
    "\n",
    "            start_time = time.time()\n",
    "\n",
    "            train_loss = train(model, train_loader, optimizer, criterion, CLIP)\n",
    "            valid_loss, _ = evaluate(model, valid_loader, criterion)\n",
    "\n",
    "            time_diff = int(time.time() - start_time)\n",
    "\n",
    "            scheduler.step()\n",
    "\n",
    "            if valid_loss + EPSILON < best_valid_loss:\n",
    "                # Save losses to result file\n",
    "                with open(TRAIN_RESULTS_PATH, \"a\") as f:\n",
    "                    f.write(f\"{combination},{fold},{epoch},{train_loss},{valid_loss},{hid_dim},{n_layers},{init_lr},{model.name}\\n\")\n",
    "\n",
    "                # Update best validation loss and save model\n",
    "                best_valid_loss = valid_loss\n",
    "                logging.info(f\"Updated best validation loss to {best_valid_loss}.\")\n",
    "                torch.save(model.state_dict(), best_model_path)\n",
    "            else:\n",
    "                logging.info(f\"End training after epoch {epoch} as validation loss does not further decrease.\")\n",
    "                logging.info(f\"Best model saved at {best_model_path}\")\n",
    "                break\n",
    "\n",
    "        time_diff = int(time.time() - overall_start_time)\n",
    "\n",
    "        # Evaluate model on test set\n",
    "        logging.info(f\"Load model from epoch {epoch-1} from {best_model_path}\")\n",
    "        model.load_state_dict(torch.load(best_model_path))\n",
    "\n",
    "        test_loss, metrics = evaluate(model, test_loader, criterion)\n",
    "        accuracy, precision, recall, f1_score = metrics\n",
    "\n",
    "        with open(TEST_RESULTS_PATH, \"a\") as f:\n",
    "            f.write(f\"{combination},{fold},{test_loss},{accuracy},{precision},{recall},{f1_score},{hid_dim},{n_layers},{init_lr},{model.name},{time_diff}\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
