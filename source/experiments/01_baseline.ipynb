{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4729d1b8",
   "metadata": {},
   "source": [
    "# Baseline Experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1d50174",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from multiprocessing import Pool\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import h5py\n",
    "from sklearn.model_selection import KFold\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "from utils import cole_kripke, sadeh, calc_metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28d31086",
   "metadata": {},
   "source": [
    "## Set gloabel variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f0f5cdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set information about the dataset\n",
    "HDF5_FILE_PATH = os.path.join(os.sep, 'home', 'data', \"ANNOTATED_BEDTIME_TU7.hdf5\")\n",
    "EPOCH_FILE_PATH = os.path.join(os.sep, 'home', 'data', \"ACTIGRAPH_EPOCHS_TU7_CLEAN.hdf5\")\n",
    "\n",
    "COLNAMES = [\"Time\", \"X\", \"Y\", \"Z\", \"Annotated Time in Bed\"]\n",
    "SAMPLE_RATE = 100\n",
    "LABEL_DICT = {False: 0, True: 1}\n",
    "EXCLUDED_DATASETS = []\n",
    "EPOCH_LENGTH = \"60s\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8f183d0",
   "metadata": {},
   "source": [
    "## Load subjects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ab79461",
   "metadata": {},
   "outputs": [],
   "source": [
    "with h5py.File(HDF5_FILE_PATH, \"r\") as hdf5_file:\n",
    "    subjects = [subject for subject in hdf5_file.keys() if subject not in EXCLUDED_DATASETS]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a9deb1f",
   "metadata": {},
   "source": [
    "## Define processing pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22d5d3e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_subject(subject):\n",
    "    try:\n",
    "        time_col, x_col, y_col, z_col, target_col = COLNAMES\n",
    "\n",
    "        data = pd.read_hdf(HDF5_FILE_PATH, key=subject)\n",
    "        data = data[[time_col, target_col]]\n",
    "\n",
    "        # Fix time format (there might be a quicker way, but it works)\n",
    "        #data.loc[:,time_col] = pd.to_datetime(data[time_col].dt.strftime('%Y-%d-%m %H:%M:%S'), format='%Y-%m-%d %H:%M:%S')\n",
    "\n",
    "        epochs = pd.read_hdf(EPOCH_FILE_PATH, key=subject)\n",
    "        epochs = epochs[[time_col, y_col]]\n",
    "\n",
    "        if min(data[time_col]).strftime('%Y-%d-%m') == min(epochs[time_col]).strftime('%Y-%m-%d'):\n",
    "            start_time = pd.Timestamp(min(data[time_col]).strftime('%Y-%d-%m %H:%M:%S')) # Apparently d and m are switched in the data.\n",
    "            data.loc[:,time_col] = pd.date_range(start_time, periods=data.shape[0], freq=\"10ms\")\n",
    "        else:\n",
    "            start_time = min(data[time_col])\n",
    "            \n",
    "        end_time = max(data[time_col])\n",
    "\n",
    "        epochs = epochs.loc[(epochs[time_col] > start_time) & (epochs[time_col] < end_time), :]\n",
    "        epochs = epochs.set_index(time_col).resample(EPOCH_LENGTH).sum()\n",
    "\n",
    "        epochs = pd.merge_asof(epochs, data, on=time_col, direction=\"nearest\")\n",
    "        epochs.loc[:, \"Counts\"] = np.clip(epochs[y_col], 0, 300)\n",
    "\n",
    "        # Predict with Sadeh algorithm\n",
    "        epochs.loc[:,\"Sadeh\"] = sadeh(epochs[\"Counts\"])\n",
    "\n",
    "        # Predict with Cole_Kripke algorithm / Divide by 100 for Cole Kripke algorithm\n",
    "        epochs.loc[:, \"Cole-Kripke\"] = cole_kripke(epochs[\"Counts\"] / 100)\n",
    "\n",
    "        results = pd.DataFrame(columns=[\"Subject\", \"Method\", \"Accuracy\", \"Precision\", \"Recall\", \"F1 Score\"])\n",
    "        results.loc[0, :] = [subject, \"Sadeh\"] + list(calc_metrics(epochs[target_col], epochs[\"Sadeh\"]))\n",
    "        results.loc[1, :] = [subject, \"Cole-Kripke\"] + list(calc_metrics(epochs[target_col], epochs[\"Cole-Kripke\"]))\n",
    "\n",
    "        return results\n",
    "\n",
    "    except Exception as msg:\n",
    "        print(f\"Problem processing {subject}: {msg}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fa9bb88",
   "metadata": {},
   "source": [
    "## Calculate Sadeh and Cole-Kripke results for each subject"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9401c9a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "with Pool(200) as p:\n",
    "    results = pd.concat(tqdm(p.imap(process_subject, subjects), total=len(subjects)), axis=0, ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75a344c2",
   "metadata": {},
   "source": [
    "## Simulate cross-validation to get an idea about the between fold variation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78d4f5af",
   "metadata": {},
   "outputs": [],
   "source": [
    "results.loc[:, \"Fold\"] = -1\n",
    "\n",
    "# Do 10-fold cross-validation\n",
    "kf = KFold(n_splits=10)\n",
    "for fold, (_, test_idx) in enumerate(kf.split(np.arange(len(subjects)))):\n",
    "    subjects_in_fold = [subjects[idx] for idx in test_idx]\n",
    "    results.loc[[subject in subjects_in_fold for subject in results[\"Subject\"]], \"Fold\"] = fold\n",
    "\n",
    "results.to_csv(\"results/exp01_baseline.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
